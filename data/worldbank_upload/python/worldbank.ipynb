{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fifteen-gamma",
   "metadata": {},
   "source": [
    "# Demonstration: using python for working with World Bank Data: plotting and data insertion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-childhood",
   "metadata": {},
   "source": [
    "## Loading dependencies of the notebook\n",
    "\n",
    "We use `pandas` to handle regular tabular data, `numpy` for numerical functionality, `wbgapi` to interact with World Bank Open Data's API and `geopandas` to handle geographical mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-plasma",
   "metadata": {},
   "outputs": [],
   "source": [
    "! bash -i -l -c \"pip install -q wbgapi pycountry && pip install -q --upgrade nuvolos-odbc && conda install -q -y descartes geopandas ffmpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wbgapi as wb\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-transfer",
   "metadata": {},
   "source": [
    "## Exploring data on using `wbgapi`\n",
    "\n",
    "`wbgapi` is a wrapper library for the World Bank Web API. For an introduction, please refer to the [vignette](https://blogs.worldbank.org/opendata/introducing-wbgapi-new-python-package-accessing-world-bank-data) of the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "FDI_GDP_PCT_info = wb.series.metadata.get('BX.KLT.DINV.WD.GD.ZS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "FDI_GDP_PCT_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "FDI_GDP_PCT_data = wb.data.DataFrame('BX.KLT.DINV.WD.GD.ZS', time=range(2000, 2020,), labels=True)\n",
    "FDI_GDP_PCT_data.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-treasure",
   "metadata": {},
   "source": [
    "## Plotting the data\n",
    "\n",
    "The plot we produce is quite similar to the one available directly on the website of the World Bank (see [source](https://data.worldbank.org/indicator/BX.KLT.DINV.CD.WD?view=map&year=2001)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "worldmap = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-clarity",
   "metadata": {},
   "source": [
    "It is possible to use `pandas` merge to merge a `geopandas` data frame with a regular `pandas` DataFrame. Once the appropriate cleanup and transformation is done, we call the `GeoDataFrame` constructor that uses the `geometry` column of `data_mapped` to as the geometry field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-honduras",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mapped = pd.merge(FDI_GDP_PCT_data, worldmap, left_on = 'economy', right_on = 'iso_a3')\n",
    "data_mapped.drop(['pop_est', 'economy', 'gdp_md_est', 'Country'], axis = 1, inplace = True)\n",
    "data_mapped = data_mapped.melt(id_vars = ['continent', 'iso_a3', 'name', 'geometry'])\n",
    "data_mapped = gpd.GeoDataFrame(data_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "FDI_GDP_PCT_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "worldmap.loc[worldmap['continent'] == 'Europe',:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-steering",
   "metadata": {},
   "source": [
    "Upon closer inspection of the resulting mapped dataframe, it turns out that while certain countries do have shapes associated with them, their 3-letter ISO code is missing. This would result in e.g. France missing from our map!\n",
    "\n",
    "## A small detour: obtaining correct ISO codes\n",
    "\n",
    "In order to correct the world map information, we first rely on the `pycountry` package that comes with smart lookup functionality and country codes in both 2 and 3 letter ISO format. Given that we only have country names available for every country, we use the `search_fuzzy` method. The method prioritizes better matches, so we take the best match and its 3 letter ISO value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-disorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_country(x):\n",
    "    import pycountry as pcc\n",
    "    try:\n",
    "        y = pcc.countries.search_fuzzy(x)[0].alpha_3\n",
    "    except Exception as e:\n",
    "        y = pd.NA\n",
    "    return y\n",
    "\n",
    "worldmap['iso_fuzzy'] = worldmap['name'].apply(lambda x: map_country(x))\n",
    "worldmap['iso_a3_na'] = worldmap['iso_a3'].replace('-99', pd.NA)\n",
    "worldmap['iso_merge'] = worldmap['iso_a3_na'].fillna(worldmap['iso_fuzzy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-scholar",
   "metadata": {},
   "source": [
    "We re-execute the merging based on the enhanced worldmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-forty",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mapped = pd.merge(FDI_GDP_PCT_data, worldmap, left_on = 'economy', right_on = 'iso_merge')\n",
    "data_mapped.drop(['pop_est', 'economy', 'gdp_md_est', 'Country', 'iso_fuzzy', 'iso_a3', 'iso_a3_na'], axis = 1, inplace = True)\n",
    "data_mapped = data_mapped.melt(id_vars = ['continent', 'iso_merge', 'name', 'geometry'])\n",
    "data_mapped = gpd.GeoDataFrame(data_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-healing",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mapped_filter = data_mapped.loc[data_mapped.loc[:,'variable'] == 'YR2000',:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-exploration",
   "metadata": {},
   "source": [
    "### Addendum: loading other base layers\n",
    "\n",
    "You can load other base layers using the `geopandas` package, see the documentation [here](https://geopandas.org/docs/user_guide/io.html). In particular, you can grab zipped ArcGIS repositories and load them directly into geopandas with the following convenience function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_load_map(url, local_zip_path):\n",
    "    import urllib.request\n",
    "    import os\n",
    "    import geopandas as gpd\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, local_zip_path)\n",
    "    except Exception as e:\n",
    "        raise(e)   \n",
    "    try:\n",
    "        frame = gpd.read_file(f\"zip:///{local_zip_path}\")\n",
    "    except Exception as e:\n",
    "        raise(e)  \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of how to use it\n",
    "yy = get_and_load_map('https://opendata.arcgis.com/datasets/2b93b06dc0dc4e809d3c8db5cb96ba69_0.zip', '/files/test.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-circulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-graphics",
   "metadata": {},
   "source": [
    "## The plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-spine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to min and max of data\n",
    "vmin, vmax = min(data_mapped_filter['value']), max(data_mapped_filter['value'])\n",
    "\n",
    "# create figure and axes for Matplotlib\n",
    "fig, ax = plt.subplots(1, figsize=(28,12))\n",
    "\n",
    "# add a title and annotation\n",
    "ax.set_title('FDI Inflow (Net, % of GDP)', fontdict={'fontsize': '25', 'fontweight' : '3'})\n",
    "\n",
    "data_mapped_filter.plot(column='value',cmap='PuBu', linewidth=1, ax=ax, edgecolor='.5')\n",
    "ax.axis('off')\n",
    "sm = plt.cm.ScalarMappable(cmap='PuBu', norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "import time\n",
    "import datetime as dt\n",
    "vmin, vmax = np.quantile(data_mapped['value'], 0.05), np.quantile(data_mapped['value'], 0.95)\n",
    "fig, ax = plt.subplots(1, figsize=(28,12))\n",
    "ax.axis('off')\n",
    "sm = plt.cm.ScalarMappable(cmap='PuBu', norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm)\n",
    "\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    data_mapped_filter = data_mapped.loc[data_mapped.loc[:,'variable'] == f'YR{i}',:]\n",
    "    ax.clear()\n",
    "    ax.set_title(f'FDI Inflow (Net, % of GDP), year {i}', fontdict={'fontsize': '25', 'fontweight' : '3'})\n",
    "    p = data_mapped_filter.plot(column='value',cmap='PuBu', linewidth=1, ax=ax, edgecolor='.5')\n",
    "    return ax\n",
    "    \n",
    "anim = FuncAnimation(fig, animate, frames=range(2000,2019,), interval=500, blit=False)\n",
    "current_time = dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "anim.save(f'FDI_plot_{current_time}.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-mongolia",
   "metadata": {},
   "source": [
    "## Storing the data\n",
    "\n",
    "Storing the data in the Scientific Data Warehouse (SDW) can be done via the nuvolos package, which comes already installed in every JupyterLab application.\n",
    "\n",
    "In this particular example, we will melt the data to be in the 'long' format, then we will store the resulting pandas DataFrame object in the SDW via a simple call. As a final step, we will provide some column comments and table comments to clarify the contents for later usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "FDI_GDP_PCT_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-patrick",
   "metadata": {},
   "outputs": [],
   "source": [
    "FDI_GDP_PCT_data_melt = FDI_GDP_PCT_data.melt(id_vars = ['economy', 'Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "FDI_GDP_PCT_data_melt['variable'] = FDI_GDP_PCT_data_melt['variable'].apply(lambda x: x.replace('YR', '')).apply(lambda x: np.int_(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-cigarette",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nuvolos\n",
    "con = nuvolos.get_connection()\n",
    "con.autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuvolos.to_sql(df = FDI_GDP_PCT_data_melt, name = \"FDI_GDP_PCT\", con = con, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-stuff",
   "metadata": {},
   "source": [
    "## Adding metadata\n",
    "\n",
    "You can add table comments and column comments to provide a short description of the fields or tables of interest. While this feature cannot serve as a complete documentation solution, it will prove very useful for data used by a large number of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-director",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = con.cursor()\n",
    "cur.execute(\"COMMENT ON COLUMN FDI_GDP_PCT.value IS 'Foreign Direct Investment as Pct of GDP'\")\n",
    "cur.execute(\"COMMENT ON COLUMN FDI_GDP_PCT.variable IS 'Time Period'\")\n",
    "cur.execute(\"COMMENT ON COLUMN FDI_GDP_PCT.economy IS 'ISO A3 Country Code'\")\n",
    "cur.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-necessity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
